{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b7dc60-de79-43a8-84bb-7e246edc018e",
   "metadata": {},
   "source": [
    "## Preparing Datasets and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4378e28d-e7a3-4159-923a-557278004fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efcfd3f-127d-4ec8-b5fc-fd4f3a35506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1636058-0024-4644-9624-0dee0f779c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\josia\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\josia\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\josia\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\josia\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\josia\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795bd3f2-0ae7-45e5-bf7d-decf185abdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv(\"data/equities.csv\")\n",
    "GICS = pd.read_excel(\"data/GICS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e679aa-363e-48dd-aa2f-6b4405028650",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list['symbol'].fillna(\"NaN\", inplace=True)\n",
    "stock_list.fillna(\" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d539f5-eb73-417a-882e-9d11c77410d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_industry = GICS[['sub_industry_code', 'sub-industry']].rename(columns={'sub_industry_code':'GicCode', 'sub-industry':'GicSubIndustry'}).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5e01c5-9a26-4f12-841a-e4a377a4b5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SHZ', 'KSC', 'HKG', 'KLS', 'KOE', 'BER', 'FRA', 'STU', ' ', 'ENX',\n",
       "       'TWO', 'HAM', 'MUN', 'DUS', 'TAI', 'PAR', 'GER', 'IOB', 'LSE',\n",
       "       'MEX', 'HAN', 'SAU', 'JPX', 'ASX', 'SAP', 'FKA', 'SES', 'TLO',\n",
       "       'VIE', 'BSE', 'OSL', 'NSI', 'STO', 'MCE', 'MIL', 'BUD', 'SHH',\n",
       "       'NYQ', 'SET', 'VAN', 'SAO', 'ISE', 'AMS', 'ATH', 'PNK', 'AQS',\n",
       "       'CPH', 'TOR', 'NGM', 'NMS', 'NCM', 'ASE', 'CSE', 'JKT', 'HEL',\n",
       "       'EBS', 'BUE', 'SGO', 'CNQ', 'NZE', 'CCS', 'JNB', 'BRU', 'TLV',\n",
       "       'DOH', 'MCX', 'NEO', 'NYS', 'IST', 'NAS', 'LIS', 'LIT', 'PRA',\n",
       "       'TAL', 'ICE', 'RIS', 'BTS', 'NSE', 'CAI', 'PCX', 'SAT', 'OBB',\n",
       "       'NAE'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list['exchange'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2a8637-fe0a-4acf-a6da-478d1ea598d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_excel(exchange, output_folder):\n",
    "    api_url = f\"https://eodhistoricaldata.com/api/exchange-symbol-list/{exchange}?api_token=64e6bb917d6ca7.00493420\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Check for any request errors\n",
    "        \n",
    "        content_disposition = response.headers.get('content-disposition')\n",
    "        if content_disposition:\n",
    "            filename = content_disposition.split('filename=')[1].replace('\"', '')  # Remove double quotes\n",
    "        else:\n",
    "            filename = f\"{exchange}_data.xlsx\"  # Fallback filename\n",
    "        \n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        with open(output_path, 'wb') as excel_file:\n",
    "            excel_file.write(response.content)\n",
    "        \n",
    "        print(f\"Excel file downloaded and saved as {filename} in {output_folder}.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "download_folder = r\"C:\\Users\\josia\\Documents\\GitHub\\BT\\BTWork\\exchanges\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb924ab9-3e1e-4f78-a621-35fe8a396f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges_full_list = ['US', 'LSE', 'AU', 'SHE','NSE', 'NEO','V', 'TO', 'BE', 'HM', 'XETRA', 'DU', 'MU', 'F', 'HA', 'STU', 'VI', 'PA', 'BR', 'MC', 'SW', 'LS', 'AS', 'ST', 'IR', 'CO', \"OL\", 'IC', 'HE',\n",
    "      'XBOT', 'SEM', 'EGX', 'GSE', 'PR', 'BRVM', 'XNAI', 'BC', 'VFEX', 'MSE', 'XNSA', 'RSE', 'DSE', 'USE', 'LUSE', 'XZIM', 'TA', 'KQ', 'KO', 'BUD', 'WAR', 'PSE', \n",
    "      'JK', 'SHG', 'JSE', 'AT', 'SN', 'BK', 'KAR', 'SR', 'CM', 'VN', 'KLSE', 'BA', 'SA', 'RO', 'MX', 'IL', 'ZSE', 'MCX', 'TWO', 'TW', 'LIM', 'IS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14000f6a-35c4-400d-83b8-4002f400e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "excluded = ['FUND', 'ETF', 'ETC', 'Mutual Fund', 'Note']\n",
    "#exchanges_full_list = ['LU']\n",
    "for i in exchanges_full_list:\n",
    "    \n",
    "    #download_excel(i, download_folder)\n",
    "    file_name = f\"{i}_LIST_OF_SYMBOLS.csv;\"\n",
    "    \n",
    "    df = pd.read_csv(f\"exchanges/{file_name}\", dtype=str)    \n",
    "    df = df[~df['Type'].isin(excluded)]\n",
    "    dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fdfa86-b1ca-4296-b430-c3285de900db",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = 0 \n",
    "for i in exchanges_full_list:\n",
    "    file_name = f\"{i}_LIST_OF_SYMBOLS.csv;\"\n",
    "    #print(dataframes[file_name]['Exchange'].unique())\n",
    "    total_rows = total_rows + len(dataframes[file_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e7cfa-c0b0-4f71-b041-c0e13bb5292e",
   "metadata": {},
   "source": [
    "## Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bbc06f1-e97a-45ae-80d4-d34ba4141b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_webpage_as_json(url, output_file, folder_name):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for any request errors\n",
    "        \n",
    "        content = response.text  # Get the content of the webpage\n",
    "        \n",
    "        # Parse content as JSON\n",
    "        json_data = json.loads(content)\n",
    "        \n",
    "        subfolder_path = os.path.join('stocks', folder_name)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        output_path = os.path.join(subfolder_path, output_file)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            with open(output_path, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(json_data, json_file, indent=4)\n",
    "            print(f\"Webpage content saved as {output_file}\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf3d314-1323-4c8d-95ca-7aa043e96e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_scrape(exchange, stock_list, exchange_code_official):\n",
    "    for i in stock_list['Code']:\n",
    "        string_start = \"https://eodhistoricaldata.com/api/fundamentals/\"\n",
    "        string_end = \"?api_token=64e6bb917d6ca7.00493420\"\n",
    "        url_string = string_start + i + \".\" + exchange + string_end\n",
    "       \n",
    "        output_filename = i + \"_\" + exchange + \".json\"\n",
    "        file_path = 'stocks/'+ exchange_code_official +\"/\"+output_filename\n",
    "        if not os.path.exists(file_path):\n",
    "            save_webpage_as_json(url_string, output_filename, exchange_code_official)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a465957-911b-4c13-b9db-9016c28db6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_dataframe(exchange, stock_list, exchange_code_official):\n",
    "    final_df = pd.DataFrame()\n",
    "    for i in stock_list['Code']:\n",
    "        \n",
    "        output_filename = i + \"_\" + exchange + \".json\"\n",
    "        file_path = 'stocks/'+ exchange_code_official +\"/\"+output_filename\n",
    "        if os.path.exists(file_path):\n",
    "            raw_data = open(file_path)\n",
    "            dict_data = json.load(raw_data)\n",
    "   \n",
    "            if len(dict_data) != 0 and 'GicSubIndustry' in dict_data['General']:\n",
    "    \n",
    "                new_dict = {'Code':dict_data['General']['Code'], 'Exchange':dict_data['General']['Exchange'], 'Name':dict_data['General']['Name'], 'GicSector':dict_data['General']['GicSector'],\n",
    "                           'GicGroup':dict_data['General']['GicGroup'],'GicIndustry':dict_data['General']['GicIndustry'],'GicSubIndustry':dict_data['General']['GicSubIndustry']}\n",
    "                        \n",
    "                final_df = final_df.append(new_dict, ignore_index = True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df03e8d-c607-4bc5-9b86-677532be0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(exchange, stocks, ex_ticker):\n",
    "    \n",
    "    df = stock_dataframe(exchange, stocks, ex_ticker)\n",
    "    df2 = pd.merge(df, sub_industry, on='GicSubIndustry', how='left').drop(columns=['GicSector', 'GicGroup', 'GicIndustry', 'GicSubIndustry'])\n",
    "    df3 = pd.merge(df2, ex_df, on='Exchange', how='left')\n",
    "    cols = {'Code':'Stock Ticker', 'Name':'Company Name', 'GicCode':'GICSCode'}\n",
    "    df3.rename(columns=cols, inplace=True)\n",
    "    df3 = df3.reindex(columns=['Stock Ticker', 'Company Name', 'Exchange Ticker', 'Exchange Name', 'GICSCode'])\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b7d03-a82a-42af-9b21-edc08345d210",
   "metadata": {},
   "source": [
    "## Stock codes for each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4010ffc-235c-4b83-9373-2393cbfdf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dict = {'Exchange':['AU','SHE','AS','AT','BA','BE','BK','BR','BUD','CM','CO','DSE','DU','F','HA','HE','HM','IC','IL','IR','IS','JK','JSE','KAR','KLSE',\n",
    "                   'KO','KQ','LIM','LS','LSE','LUSE','MC','MCX','MSE','MU','MX','NEO','OL','PA','PR','PSE','RO','RSE','SA','SEM','SHG','SN','SR',\n",
    "                   'ST','STU','SW','TA','TO','TW','TWO','V','VI','VN','WAR','XBOT','XETRA','XNAI','XNSA','ZSE', 'NSE',\n",
    "                   'NYSE','NASDAQ','NYSE ARCA','NYSE MKT','OTCQX','OTCCE','OTCGREY','OTCMKTS','OTCQB'],\n",
    "                   \n",
    "         \n",
    "         'Exchange Ticker': ['ASX','SHE','AMS','ATH','BUE','BER','BKK','BRU','BDP','COL','CPH','DSE','DUS','FRA','HAN','HEL','HAM','ISM','IL','DUB','IST','JKT',\n",
    "                      'JSE','KAR','KLSE','KRX','KOSDAQ','LIM','ELI','LSE','LUSE','BME','MCX','MSE','MUN','BMV','NEO','OSL','EPA','PRG','PSE','BSE',\n",
    "                      'RSE','BVMF','SEM','SHG','SSE','TASI','STO','STU','SWX','TLV','TSE','TPE','TWO','TSX','VIE','VSE','WSE','XBOT','XETRA','XNAI','XNSA','ZSE', 'NSE',\n",
    "                      'NYSE', 'NASDAQ', 'NYSE ARCA', 'NYSE MKT', 'OTCQX', 'OTCCE','OTCGREY','OTCMKTS','OTCQB'], \n",
    "                 \n",
    "         'Exchange Name':['Australia Securities Exchange', 'Shenzhen Stock Exchange', 'Euronext Amsterdam','Athens Exchange', 'Bolsa de Comercio de Buenos Aires', 'Boerse Berlin', \n",
    "                         'Stock Exchange of Thailand', 'Euronext Brussels', 'Budapest Stock Exchange', 'Colombo Stock Exchange', 'Nasdaq Copenhagen', 'Dar es Salaam Stock Exchange',\n",
    "                          'Dusseldorf Stock Exchange', 'Frankfurt Stock Exchange','Hanover Stock Exchange', 'Nasdaq Helsinki','Hamburg Stock Exchange', 'Nasdaq Iceland', \n",
    "                          'London International Stock Exchange','Euronext Dublin', 'Borsa Istanbul', 'Indonesia Stock Exchange','Johannesbug Stock Exchange', 'Pakistan Stock Exchange',\n",
    "                          'Bursa Malaysia', 'Korea Exchange', 'KOSDAQ', 'Bolsa De Valores De Lima','Euronext Lisbon','London Stock Exchange',\n",
    "                          'Lusaka Stock Exchange', 'Madrid Exchange','Moscow Exchange', 'Malawi Stock Exchange', 'Munich Stock Exchange','Bolsa Mexicana Del Valores', 'NEO Exchange',\n",
    "                          'Oslo Bors Asa','Euronext Paris','Prague Stock Exchange','Philippines Stock Exchange', 'Bursa de Valori Bucuresti', 'Rwanda Stock Exchange',\n",
    "                          'B3 S.A. – Brasil, Bolsa, Balcão', 'Stock Exchange of Mauritius', 'Shanghai Stock Exchange', 'Bolsa de Santiago', 'Tadawul (Saudi Arabia)', 'Nasdaq Stockholm',\n",
    "                          'Stuttgart Stock Exchange', 'SIX Swiss Exchange', 'Tel Aviv Stock Exchange', 'Toronto Stock Exchange','Taipei Exchange','Taiwan Stock Exchange','TSX Venture',\n",
    "                          'Vienna Stock Exchange','Ho Chi Minh City Stock Exchange','Warsaw Stock Exchange', 'Botswanna Stock Exchange','Deutsche Boerse Xetra','Nairobi Stock Exchange',\n",
    "                          'Nigeria Stock Exchange','Zagreb Stock Exchange', 'National Stock Exchange of India',\n",
    "                          'New York Stock Exchage', 'NASDAQ', 'NYSE ARCA', 'NYSE MKT', 'OTCQX', 'OTCCE', 'OTCGREY', 'OTCMKTS', 'OTCBQ']}\n",
    "                         \n",
    "ex_df = pd.DataFrame(ex_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "980c4b0e-8877-4388-89e8-ae158a526a7a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "excluded_exchange = ['PINK']\n",
    "dataframes['US_LIST_OF_SYMBOLS.csv;'] = dataframes['US_LIST_OF_SYMBOLS.csv;'][~dataframes['US_LIST_OF_SYMBOLS.csv;']['Exchange'].isin(excluded_exchange)]\n",
    "\n",
    "us_codes = dataframes['US_LIST_OF_SYMBOLS.csv;']\n",
    "asx_codes = dataframes['AU_LIST_OF_SYMBOLS.csv;']  # Australia\n",
    "she_codes = dataframes['SHE_LIST_OF_SYMBOLS.csv;'] # Shenzhen\n",
    "nse_code = dataframes['NSE_LIST_OF_SYMBOLS.csv;'] # India\n",
    "ams_codes = dataframes['AS_LIST_OF_SYMBOLS.csv;']  # Amsterdam\n",
    "ath_codes = dataframes['AT_LIST_OF_SYMBOLS.csv;']  # Athens\n",
    "bue_codes = dataframes['BA_LIST_OF_SYMBOLS.csv;']  # Buenos Aires\n",
    "ber_codes = dataframes['BE_LIST_OF_SYMBOLS.csv;']  # Berlin\n",
    "bkk_codes = dataframes['BK_LIST_OF_SYMBOLS.csv;']  # Bangkok\n",
    "bru_codes = dataframes['BR_LIST_OF_SYMBOLS.csv;']  # Brussels\n",
    "bdp_codes = dataframes['BUD_LIST_OF_SYMBOLS.csv;'] # Budapest\n",
    "col_codes = dataframes['CM_LIST_OF_SYMBOLS.csv;']  # Sri Lanka / Colombo\n",
    "cph_codes = dataframes['CO_LIST_OF_SYMBOLS.csv;']  # Denmark / Copenhagen\n",
    "dse_codes = dataframes['DSE_LIST_OF_SYMBOLS.csv;'] # Tanzania / Dar es Salaam\n",
    "dus_codes = dataframes['DU_LIST_OF_SYMBOLS.csv;']  # Dusseldorf\n",
    "fra_codes = dataframes['F_LIST_OF_SYMBOLS.csv;']   # Frankfurt\n",
    "han_codes = dataframes['HA_LIST_OF_SYMBOLS.csv;']  # Hanover\n",
    "hel_codes = dataframes['HE_LIST_OF_SYMBOLS.csv;']  # Helsinki\n",
    "ham_codes = dataframes['HM_LIST_OF_SYMBOLS.csv;']  # Hamburg\n",
    "ice_codes = dataframes['IC_LIST_OF_SYMBOLS.csv;']  # Iceland\n",
    "il_codes = dataframes['IL_LIST_OF_SYMBOLS.csv;']  # London International\n",
    "dub_codes = dataframes['IR_LIST_OF_SYMBOLS.csv;']  # Ireland\n",
    "ist_codes = dataframes['IS_LIST_OF_SYMBOLS.csv;']  # Istanbul\n",
    "jkt_codes = dataframes['JK_LIST_OF_SYMBOLS.csv;']  # Jakarta\n",
    "jse_codes = dataframes['JSE_LIST_OF_SYMBOLS.csv;'] #Johannesburg\n",
    "kar_codes = dataframes['KAR_LIST_OF_SYMBOLS.csv;'] # Pakistan / Karachi\n",
    "klse_codes = dataframes['KLSE_LIST_OF_SYMBOLS.csv;']# Malaysia\n",
    "krx_codes = dataframes['KO_LIST_OF_SYMBOLS.csv;'] # Korea SE\n",
    "kosdaq_codes = dataframes['KQ_LIST_OF_SYMBOLS.csv;'] #KOSDAQ\n",
    "lim_codes = dataframes['LIM_LIST_OF_SYMBOLS.csv;'] # Lima\n",
    "eli_codes = dataframes['LS_LIST_OF_SYMBOLS.csv;'] # Lisbon\n",
    "lse_codes = dataframes['LSE_LIST_OF_SYMBOLS.csv;'] # London SE\n",
    "#luxse_codes = dataframes['LU_LIST_OF_SYMBOLS.csv;'] # Luxembourg  - all funds (no GICS)\n",
    "luse_codes = dataframes['LUSE_LIST_OF_SYMBOLS.csv;'] # Zambia / Lusaka\n",
    "bme_codes = dataframes['MC_LIST_OF_SYMBOLS.csv;']  # Madrid / Bolsa de Madrid\n",
    "mcx_codes = dataframes['MCX_LIST_OF_SYMBOLS.csv;'] # Russia\n",
    "mse_codes = dataframes['MSE_LIST_OF_SYMBOLS.csv;'] # Malawi SE\n",
    "mun_codes = dataframes['MU_LIST_OF_SYMBOLS.csv;'] # Munich\n",
    "bmv_codes = dataframes['MX_LIST_OF_SYMBOLS.csv;'] # Bolsa Mexicana De Valores\n",
    "neo_codes = dataframes['NEO_LIST_OF_SYMBOLS.csv;'] # Canada\n",
    "osl_codes = dataframes['OL_LIST_OF_SYMBOLS.csv;'] # Norway / Oslo\n",
    "epa_codes = dataframes['PA_LIST_OF_SYMBOLS.csv;'] # Paris\n",
    "prg_codes = dataframes['PR_LIST_OF_SYMBOLS.csv;'] # Prague\n",
    "pse_codes = dataframes['PSE_LIST_OF_SYMBOLS.csv;'] # Philippines\n",
    "bse_codes = dataframes['RO_LIST_OF_SYMBOLS.csv;'] # Romania / Bucharest\n",
    "rse_codes = dataframes['RSE_LIST_OF_SYMBOLS.csv;'] # Rwanda\n",
    "bvmf_codes = dataframes['SA_LIST_OF_SYMBOLS.csv;'] # Sao Paulo\n",
    "sem_codes = dataframes['SEM_LIST_OF_SYMBOLS.csv;'] # SE Mauritius\n",
    "shg_codes = dataframes['SHG_LIST_OF_SYMBOLS.csv;'] # Shanghai\n",
    "sse_codes = dataframes['SN_LIST_OF_SYMBOLS.csv;'] # Chile / santiago\n",
    "tasi_codes = dataframes['SR_LIST_OF_SYMBOLS.csv;'] # Saudi arabia\n",
    "sto_codes = dataframes['ST_LIST_OF_SYMBOLS.csv;'] # Stockholm\n",
    "stu_codes = dataframes['STU_LIST_OF_SYMBOLS.csv;'] # Stuttgart\n",
    "swx_codes = dataframes['SW_LIST_OF_SYMBOLS.csv;'] # Switzerland\n",
    "tlv_codes = dataframes['TA_LIST_OF_SYMBOLS.csv;'] # Israel\n",
    "tse_codes = dataframes['TO_LIST_OF_SYMBOLS.csv;'] # Toronto\n",
    "tpe_codes = dataframes['TW_LIST_OF_SYMBOLS.csv;'] # Taipei\n",
    "two_codes = dataframes['TWO_LIST_OF_SYMBOLS.csv;'] # Taiwan\n",
    "tsx_codes = dataframes['V_LIST_OF_SYMBOLS.csv;'] # TSX Venture\n",
    "vie_codes = dataframes['VI_LIST_OF_SYMBOLS.csv;'] # Vienna\n",
    "vse_codes = dataframes['VN_LIST_OF_SYMBOLS.csv;'] # Ho chi minh\n",
    "wse_codes = dataframes['WAR_LIST_OF_SYMBOLS.csv;'] # Warsaw\n",
    "xbot_codes = dataframes['XBOT_LIST_OF_SYMBOLS.csv;'] # Botswanna\n",
    "xetra_codes = dataframes['XETRA_LIST_OF_SYMBOLS.csv;'] # Deutche Boerse Xetra\n",
    "xnai_codes = dataframes['XNAI_LIST_OF_SYMBOLS.csv;'] # Kenya\n",
    "xnsa_codes = dataframes['XNSA_LIST_OF_SYMBOLS.csv;'] # Nigeria\n",
    "zse_codes = dataframes['ZSE_LIST_OF_SYMBOLS.csv;'] # Zagreb\n",
    "nse_codes = dataframes['NSE_LIST_OF_SYMBOLS.csv;'] # India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4499ae2a-0f0c-4b23-b5a2-f7b86282c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tse_codes['Code'].fillna(\"NA\", inplace=True)\n",
    "us_codes['Exchange'].fillna(\"US\", inplace=True)\n",
    "us_codes['Code'].fillna(\"NAN\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0321e2-1825-4ef8-873a-a7b64675b208",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee8354b-fb8d-45bf-a736-134263fe5017",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_scrape(\"AU\", asx_codes, \"ASX\")\n",
    "json_scrape(\"SHE\", she_codes, \"SHE\")\n",
    "json_scrape('AS', ams_codes, 'AMS')\n",
    "json_scrape('AT', ath_codes, 'ATH')\n",
    "json_scrape('BA', bue_codes, 'BUE')\n",
    "json_scrape('BE', ber_codes, 'BER')\n",
    "json_scrape('BK', bkk_codes, 'BKK')\n",
    "json_scrape('BR', bru_codes, 'BRU')\n",
    "json_scrape('BUD', bdp_codes, 'BDP')\n",
    "json_scrape('CM', col_codes, 'COL')\n",
    "json_scrape('CO', cph_codes, 'CPH')\n",
    "json_scrape('DSE', dse_codes, 'DSE')\n",
    "json_scrape('DU', dus_codes, 'DUS')\n",
    "json_scrape('F', fra_codes, 'FRA')\n",
    "json_scrape('HA', han_codes, 'HAN')\n",
    "json_scrape('HE', hel_codes, 'HEL')\n",
    "json_scrape('HM', ham_codes, 'HAM')\n",
    "json_scrape('IC', ice_codes, 'ICE')\n",
    "json_scrape('IL', il_codes, 'IL')\n",
    "json_scrape('IR', dub_codes, 'DUB')\n",
    "json_scrape('IS', ist_codes, 'IST')\n",
    "json_scrape('JK', jkt_codes, 'JKT')\n",
    "json_scrape('JSE', jse_codes, 'JSE')\n",
    "json_scrape('KAR', kar_codes, 'KAR')\n",
    "json_scrape('KLSE', klse_codes, 'KLSE')\n",
    "json_scrape('KO', krx_codes, 'KRX')\n",
    "json_scrape('KQ', kosdaq_codes, 'KOSDAQ')\n",
    "json_scrape('LIM', lim_codes, 'LIM')\n",
    "json_scrape('LS', eli_codes, 'ELI')\n",
    "json_scrape('LSE', lse_codes, 'LSE')\n",
    "json_scrape('LUSE', luse_codes, 'LUSE')\n",
    "json_scrape('MC', bme_codes, 'BME')\n",
    "json_scrape('MC', bme_codes, 'BME')\n",
    "json_scrape('MCX', mcx_codes, 'MCX')\n",
    "json_scrape('MSE', mse_codes, 'MSE')\n",
    "json_scrape('MU', mun_codes, 'MUN')\n",
    "json_scrape('MX', bmv_codes, 'BMV')\n",
    "json_scrape('NEO', neo_codes, 'NEO')\n",
    "json_scrape('OL', osl_codes, 'OSL')\n",
    "json_scrape('PA', epa_codes, 'EPA')\n",
    "json_scrape('PR', prg_codes, 'PRG')\n",
    "json_scrape('PSE', pse_codes, 'PSE')\n",
    "json_scrape('RO', bse_codes, 'BSE')\n",
    "json_scrape('RSE', rse_codes, 'RSE')\n",
    "json_scrape('SA', bvmf_codes, 'BVMF')\n",
    "json_scrape('SEM', sem_codes, 'SEM')\n",
    "json_scrape('SHG', shg_codes, 'SHG')\n",
    "json_scrape('SN', sse_codes, 'SSE')\n",
    "json_scrape('SR', tasi_codes, 'TASI')\n",
    "json_scrape('ST', sto_codes, 'STO')\n",
    "json_scrape('STU', stu_codes, 'STU')\n",
    "json_scrape('SW', swx_codes, 'SWX')\n",
    "json_scrape('TA', tlv_codes, 'TLV')\n",
    "json_scrape('TO', tse_codes, 'TSE')\n",
    "json_scrape('TW', tpe_codes, 'TPE')\n",
    "json_scrape('TWO', two_codes, 'TWO')\n",
    "json_scrape('V', tsx_codes, 'TSX')\n",
    "json_scrape('VI', vie_codes, 'VIE')\n",
    "json_scrape('VN', vse_codes, 'VSE')\n",
    "json_scrape('WAR', wse_codes, 'WSE')\n",
    "json_scrape('XBOT', xbot_codes, 'XBOT')\n",
    "json_scrape('XETRA', xetra_codes, 'XETRA')\n",
    "json_scrape('XNAI', xnai_codes, 'XNAI')\n",
    "json_scrape('XNSA', xnsa_codes, 'XNSA')\n",
    "json_scrape('ZSE', zse_codes, 'ZSE')\n",
    "json_scrape('NSE', nse_codes, 'NSE')\n",
    "json_scrape('US', us_codes, \"US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50413180-f000-4e88-82a8-2cf54c5cb900",
   "metadata": {},
   "source": [
    "## GICS Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2c73b6-1087-4b30-95fd-c352d8f845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with weird US stuff\n",
    "\n",
    "usa_unf = stock_dataframe('US', us_codes, 'US')\n",
    "\n",
    "usa_drop = ['AMEX','BATS', 'US', 'NMFQS']\n",
    "usa = usa_unf[~usa_unf['Exchange'].isin(usa_drop)]\n",
    "\n",
    "usa2 = pd.merge(usa, sub_industry, on='GicSubIndustry', how='left').drop(columns=['GicSector', 'GicGroup', 'GicIndustry', 'GicSubIndustry'])\n",
    "usa3 = pd.merge(usa2, ex_df, on='Exchange', how='left')\n",
    "cols = {'Code':'Stock Ticker', 'Name':'Company Name', 'GicCode':'GICSCode'}\n",
    "usa3.rename(columns=cols, inplace=True)\n",
    "usa3 = usa3.reindex(columns=['Stock Ticker', 'Company Name', 'Exchange Ticker', 'Exchange Name', 'GICSCode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88b6a7b-9e48-4799-8799-ee5177bf31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asx = formatting('AU', asx_codes, 'ASX')\n",
    "ams = formatting('AS', ams_codes, 'AMS')\n",
    "ath = formatting('AT', ath_codes, 'ATH')\n",
    "bue = formatting('BA', bue_codes, 'BUE')\n",
    "ber = formatting('BE', ber_codes, 'BER')\n",
    "bkk = formatting('BK', bkk_codes, 'BKK')\n",
    "bru = formatting('BR', bru_codes, 'BRU')\n",
    "bdp = formatting('BUD', bdp_codes, 'BDP')\n",
    "she = formatting(\"SHE\", she_codes, \"SHE\")\n",
    "col = formatting('CM', col_codes, 'COL')\n",
    "cph = formatting('CO', cph_codes, 'CPH')\n",
    "dse = formatting('DSE', dse_codes, 'DSE')\n",
    "dus = formatting('DU', dus_codes, 'DUS')\n",
    "fra = formatting('F', fra_codes, 'FRA')\n",
    "han = formatting('HA', han_codes, 'HAN')\n",
    "hel = formatting('HE', hel_codes, 'HEL')\n",
    "ham = formatting('HM', ham_codes, 'HAM')\n",
    "ice = formatting('IC', ice_codes, 'ICE')\n",
    "il = formatting('IL', il_codes, 'IL')\n",
    "dub = formatting('IR', dub_codes, 'DUB')\n",
    "ist = formatting('IS', ist_codes, 'IST')\n",
    "jkt = formatting('JK', jkt_codes, 'JKT')\n",
    "jse = formatting('JSE', jse_codes, 'JSE')\n",
    "kar = formatting('KAR', kar_codes, 'KAR')\n",
    "klse = formatting('KLSE', klse_codes, 'KLSE')\n",
    "krx = formatting('KO', krx_codes, 'KRX')\n",
    "kosdaq = formatting('KQ', kosdaq_codes, 'KOSDAQ')\n",
    "lim = formatting('LIM', lim_codes, 'LIM')\n",
    "eli = formatting('LS', eli_codes, 'ELI')\n",
    "lse = formatting('LSE', lse_codes, 'LSE')\n",
    "\n",
    "luse = formatting('LUSE', luse_codes, 'LUSE')\n",
    "bme = formatting('MC', bme_codes, 'BME')\n",
    "mcx = formatting('MCX', mcx_codes, 'MCX')\n",
    "mse = formatting('MSE', mse_codes, 'MSE')\n",
    "mun = formatting('MU', mun_codes, 'MUN')\n",
    "bmv = formatting('MX', bmv_codes, 'BMV')\n",
    "neo = formatting('NEO', neo_codes, 'NEO')\n",
    "osl = formatting('OL', osl_codes, 'OSL')\n",
    "epa = formatting('PA', epa_codes, 'EPA')\n",
    "prg = formatting('PR', prg_codes, 'PRG')\n",
    "pse = formatting('PSE', pse_codes, 'PSE')\n",
    "bse = formatting('RO', bse_codes, 'BSE')\n",
    "rse = formatting('RSE', rse_codes, 'RSE')\n",
    "bvmf = formatting('SA', bvmf_codes, 'BVMF')\n",
    "sem = formatting('SEM', sem_codes, 'SEM')\n",
    "shg = formatting('SHG', shg_codes, 'SHG')\n",
    "sse = formatting('SN', sse_codes, 'SSE')\n",
    "tasi = formatting('SR', tasi_codes, 'TASI')\n",
    "sto = formatting('ST', sto_codes, 'STO')\n",
    "stu = formatting('STU', stu_codes, 'STU')\n",
    "swx = formatting('SW', swx_codes, 'SWX')\n",
    "tlv = formatting('TA', tlv_codes, 'TLV')\n",
    "tse = formatting('TO', tse_codes, 'TSE')\n",
    "tpe = formatting('TW', tpe_codes, 'TPE')\n",
    "two = formatting('TWO', two_codes, 'TWO')\n",
    "tsx = formatting('V', tsx_codes, 'TSX')\n",
    "vie = formatting('VI', vie_codes, 'VIE')\n",
    "vse = formatting('VN', vse_codes, 'VSE')\n",
    "wse = formatting('WAR', wse_codes, 'WSE')\n",
    "xbot = formatting('XBOT', xbot_codes, 'XBOT')\n",
    "xetra = formatting('XETRA', xetra_codes, 'XETRA')\n",
    "xnai = formatting('XNAI', xnai_codes, 'XNAI')\n",
    "xnsa = formatting('XNSA', xnsa_codes, 'XNSA')\n",
    "zse = formatting('ZSE', zse_codes, 'ZSE')\n",
    "nse = formatting('NSE', nse_codes, 'NSE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab233def-21d3-4a91-a240-3b3723a3c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with weird exchange notations in each STO and CPH\n",
    "\n",
    "sto['Exchange Ticker'] = 'STO'\n",
    "sto['Exchange Name'] = 'Nasdaq Stockholm'\n",
    "\n",
    "cph['Exchange Ticker'] = 'CPH'\n",
    "cph['Exchange Name'] = 'Nasdaq Copenhagen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b1729f-89b1-44f9-bcba-abb033b4612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of all exchanges except US\n",
    "exch = {'ASX':asx,'SHE':she,'AMS':ams,'ATH':ath,'BUE':bue,'BER':ber,'BKK':bkk,'BRU':bru,'BDP':bdp,'COL':col,'CPH':cph,'DSE':dse,'DUS':dus,'FRA':fra,'HAN':han,\n",
    "        'HEL':hel,'HAM':ham,'ICE':ice,'IL':il,'DUB':dub,'IST':ist,'JKT':jkt, 'JSE':jse,'KAR':kar,'KLSE':klse,'KRX':krx,'KOSDAQ':kosdaq,'LIM':lim,'ELI':eli,\n",
    "        'LSE':lse,'LUSE':luse,'BME':bme,'MCX':mcx,'MSE':mse,'MUN':mun,'BMV':bmv,'NEO':neo,'OSL':osl,'EPA':epa,'PRG':prg,'PSE':pse,'BSE':bse,'RSE':rse,'BVMF':bvmf,\n",
    "        'SEM':sem,'SHG':shg,'SSE':sse,'TASI':tasi,'STO':sto,'STU':stu,'SWX':swx,'TLV':tlv,'TSE':tse,'TPE':tpe,'TWO':two,'TSX':tsx,'VIE':vie,'VSE':vse,'WSE':wse,'XBOT':xbot,'XETRA':xetra,\n",
    "        'XNAI':xnai,'XNSA':xnsa,'ZSE':zse, 'NSE':nse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9a0f7dc-6959-48c3-be83-2eba024f91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all dataframes into a list\n",
    "\n",
    "stock_gic = []\n",
    "for index, row in ex_df.iterrows():\n",
    "    df_name = row['Exchange Ticker']\n",
    "    if df_name in exch:\n",
    "        stock_gic.append(exch[df_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da55bcf-f272-4d93-8e96-84c4efe440f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all exchanges except US\n",
    "\n",
    "stock_gic_df = pd.concat(stock_gic, ignore_index=True) #.sort_values(by='Exchange Ticker',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f41d1100-c8f7-4a0e-a532-55c2ee02b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding US Stocks cause tricky\n",
    "\n",
    "stock_gic_df_final = pd.concat([stock_gic_df, usa3], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa52fd7c-c9b9-4108-ad91-ad8aff02d61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Ticker</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Exchange Ticker</th>\n",
       "      <th>Exchange Name</th>\n",
       "      <th>GICSCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14D</td>\n",
       "      <td>1414 Degrees Ltd</td>\n",
       "      <td>ASX</td>\n",
       "      <td>Australia Securities Exchange</td>\n",
       "      <td>55105010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1AD</td>\n",
       "      <td>AdAlta Ltd</td>\n",
       "      <td>ASX</td>\n",
       "      <td>Australia Securities Exchange</td>\n",
       "      <td>35201010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1AE</td>\n",
       "      <td>Aurora Energy Metals Ltd</td>\n",
       "      <td>ASX</td>\n",
       "      <td>Australia Securities Exchange</td>\n",
       "      <td>10102050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1AG</td>\n",
       "      <td>Alterra Ltd</td>\n",
       "      <td>ASX</td>\n",
       "      <td>Australia Securities Exchange</td>\n",
       "      <td>20201050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CG</td>\n",
       "      <td>One Click Group Ltd.</td>\n",
       "      <td>ASX</td>\n",
       "      <td>Australia Securities Exchange</td>\n",
       "      <td>45103010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Ticker              Company Name Exchange Ticker  \\\n",
       "0          14D          1414 Degrees Ltd             ASX   \n",
       "1          1AD                AdAlta Ltd             ASX   \n",
       "2          1AE  Aurora Energy Metals Ltd             ASX   \n",
       "3          1AG               Alterra Ltd             ASX   \n",
       "4          1CG      One Click Group Ltd.             ASX   \n",
       "\n",
       "                   Exchange Name  GICSCode  \n",
       "0  Australia Securities Exchange  55105010  \n",
       "1  Australia Securities Exchange  35201010  \n",
       "2  Australia Securities Exchange  10102050  \n",
       "3  Australia Securities Exchange  20201050  \n",
       "4  Australia Securities Exchange  45103010  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_gic_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a9d783c-a73b-4aca-80d0-b69a5fdbe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_gic_df_final.to_csv('data/StockGICS.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
